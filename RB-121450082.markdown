# **Teknologi Basis Data**
Nama : Kirana Ratu Malhanny

NIM : 121450082

Kelas : RB

# **Three Ways of Storing and Accessing Lots of Images in Python**

## Latar Belakang
Menyimpan dan mengakses gambar dalam Python bukanlah masalah besar. Python menyediakan Python Imaging Library (PIL) untuk menangani ratusan gambar tanpa kesulitan. Memilih untuk menyimpan gambar dalam format .png atau .jpg di disk adalah pilihan yang baik.

Namun, dengan berkembangnya teknologi, kebutuhan akan jumlah gambar semakin besar. Algoritma seperti Convolutional Neural Networks (CNNs) dapat mengolah dataset gambar yang besar, seperti yang ada dalam ImageNet yang terdiri dari lebih dari 14 juta gambar.

PIL tidak mampu menangani jumlah gambar sebesar itu dengan mudah. Bayangkan berapa lama waktu yang diperlukan untuk memuat semua gambar tersebut ke dalam memori untuk proses pelatihan, terutama saat memprosesnya dalam batch besar. Oleh karena itu, beberapa metode telah dikembangkan untuk menyimpan dan mengakses gambar dalam jumlah besar di Python.

## Setup
Dataset yang dipakai merupakan Canadian Institute for Advanced Research image dataset atau dikenal sebagai CIFAR-10. Berisi 60,000 gambar dengan 32x32 ukuran pixel, didalamnya terdapat beragam kelas objek seperti pesawat, anjing, mobil, kusing dan sebagainya.

Berikut adalah kode untuk mengesktrak 5 batch dataset dan memasukkan gambar menjadi numpy array.

```python
import numpy as np
import pickle
from pathlib import Path

data_dir = Path("/content/path/to/extract/directory/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

Output: \
![alt text](1.png)

```python
pip install pillow
```

## **Getting Started With LMDB**
LMDB, disebut juga sebagai "Lightning Database," adalah singkatan dari Lightning Memory-Mapped Database karena kecepatannya dan penggunaan file yang dipetakan ke memori. Ini adalah key-value store bagi basis data non-relasional. Dalam implementasinya, LMDB adalah pohon B+, di mana setiap elemen kunci-nilai adalah node dalam struktur grafik pohon. Kunci komponen B+ tree diatur sesuai dengan ukuran halaman sistem operasi, untuk efisiensi akses. LMDB memperoleh efisiensi dari pemetaan memori, mengembalikan pointer langsung ke alamat memori kunci dan nilai, tanpa perlu menyalin memori.

```python
pip install lmdb
```

## **Getting Started With HDF5**
HDF5 adalah singkatan dari Hierarchical Data Format. HDF berasal dari National Center for Supercomputing Applications yang digunakan sebagai format data ilmiah yang mudah dipindahkan dan ringkas. HDF5 sering digunakan, termasuk dalam proyek Data Bumi NASA.

File HDF terdiri dari dua jenis objek: \
**1. Dataset (array multidimensi**)\
**2. Grup**. \
Array multidimensi dari berbagai ukuran dan jenis dapat disimpan sebagai dataset, dengan syarat dimensinya seragam. Meskipun demikian, keberagaman tetap bisa didapat karena grup dan dataset bisa bersarang(nested)

```python
pip install h5py
```

## **Storing A Single Image**
Dalam proses ini, kita akan memeriksa perbandingan kuantitatif dari beberapa tugas dasar yang penting, yaitu:

1. Durasi baca dan tulis file.
2. Penggunaan memori disk.

Ketika kita berbicara tentang "file," kita fokus pada sejumlah besar file. Namun, penting untuk memahami perbedaannya karena beberapa metode mungkin dioptimalkan untuk operasi dan jumlah file yang berbeda.

Dalam eksperimen ini, kita akan membandingkan kinerja di antara berbagai jumlah file, mulai dari satu gambar hingga 100.000 gambar. Mengingat kita memiliki lima kelompok CIFAR-10 dengan total 50.000 gambar, kita dapat menggunakan setiap gambar dua kali untuk mencapai total 100.000 gambar.

```python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```

```python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```

### **Storing to disk**
```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```
Pada pengaplikasiannya, diperlukan perhatian pada meta data. Meta data yang terlampir pada gambar, yang dalam dataset contoh adalah label gambar. Ketika menyimpan gambar ke disk, ada beberapa opsi untuk menyimpan meta data. Ada beberapa opsi dalam penyimpanan metadata tersebut. Salah satu solusinya adalah dengan mengkodekan label ke dalam nama gambar seperti yang dilakukan diatas.

### **Storing to LMDB**
Kunci akan menjadi pengenal unik untuk setiap gambar, dan nilai akan menjadi gambar itu sendiri. Baik kunci maupun nilai diharapkan berupa string, sehingga LMDB akan mengonversi nilai menjadi string saat menyimpan, dan mengembalikannya ke bentuk semula saat membacanya kembali.
```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```
Kedua, database harus tahu seberapa besar memori yang akan digunakan, sesuai dengan prinsip LMDB yaitu memory-mapped.

```python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

### **Storing WIth HDF5**
Storing gambar dengan metode HDF5

```python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

### **Experiments for Storing a Single Image**

```python
# Menggabungkan 3 fungsi sebelumnya menjadi sebuah dictionary
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```

```python
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
Output:
![alt text](2.png)

## **Storing Many Images**

### Adjusting the Code for Many Images

```python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before â€” but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```

### **Preparing the Dataset**

```python
#Menggandakan dataset supaya bisa melakukan test pada 100.000 gambar
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```
Output: 
![alt text](3.png)

### **Experiment for Storing Many Images**

```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```
Output:
![alt text](4.png)

Lalu, berapakah waktu yang digunakan untuk proses storing?

```python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```
![alt text](5.png)
Generate graf pertama menampilkan perbedaan drastis antara storing png files dan LMBD atau HDF5.

![alt text](6.png)
Graf kedua menunjukan log dari timing, menoroti bahwa HDF5 mulai lebih pelan dari LMDB, namun dengan kuantitas proses yang lebih besar.

## **Reading a Single Image**

### **Reading From Disk**
Pertama, baca satu gambar dan metadatanya dari file png atau csv
```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

### **Reading From LMDB**

Kedua, baca gambar dan meta yang sama dengan LMDB. Metode ini membuka environment dan mulai membaca transaksi gambar.


```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

### **Reading From HDF5**

```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```
Untuk mengakses dataset yang beragam, dibutuhkan indexing file objek menggunakan forward slash(/)

```python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

### **Experiment for Reading a Single Image**

```python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
Output:
![](<Screenshot 2024-05-29 004727.png>)

Didapatkan waktu yang digunakan oleh tiap metode. Dibuktikan bahwa menggunakan HDF5, waktu yang digunakan lebih cepat daripada metode lain yaitu 0.007381115000498539.

## **Reading Many Images**

### **Adjusting the Code for Many Images** 

```python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```

### **Experiment for Reading Many Images**

```python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```
Output:
![](7.png)

Didapatkan hasil dari hasil membaca many images dari berbagai metode. Hasil dapat dibaca dengan plot:

```python
disk_x_r = read_many_timings["disk"]
lmdb_x_r = read_many_timings["lmdb"]
hdf5_x_r = read_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Read time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Log read time",
    log=True,
)
```
![alt text](8.png)
Dari plot diatas, menunjukkan plot normal, dimana ada perbedaan drastis antara membaca file png dan LMDB atau HDF5.

![alt text](9.png)
Sedangkan, graf kedua, menunjukkan log of timings, menyoroti perbedaan relatif dengan gambar yang lebih sedikit. Dapat dilihat bahwa HDF5 mulai agak terlambar, namun dengan bertambahnya gambar, HDF5 menjadi lebih cepat secara konsisten, lebih cepat dari LMDB dengan margin yang kecil.

## **Considering Disk Usage**

Kecepatan bukanlah satu-satunya faktor yang penting dalam hal kinerja. Saat kita memiliki dataset yang besar, seperti contohnya dataset gambar yang mencapai 3TB, kita juga harus mempertimbangkan aspek penyimpanan. Bayangkan Anda memiliki banyak gambar yang tersimpan dalam hard drive Anda. Untuk meningkatkan kinerjanya, Anda mungkin ingin membuat salinan gambar-gambar tersebut dengan menggunakan metode penyimpanan yang berbeda. Namun, perlu diingat bahwa ini juga berarti Anda harus memastikan bahwa hard drive Anda memiliki ruang yang cukup untuk menyimpan semua salinan tersebut.
